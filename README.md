# å•†å“ç›¸ä¼¼åº¦è®¡ç®—ç³»ç»Ÿ / Product Similarity Calculation System

## ç³»ç»Ÿæ¦‚è¿° / System Overview
æœ¬ç³»ç»Ÿå®ç°äº†ä»ä¸¤ä¸ªæ•°æ®åº“è¡¨ä¸­æå–å•†å“æ•°æ®ï¼Œé€šè¿‡åŒå±‚å¾ªç¯æ¯”å¯¹è®¡ç®—å•†å“ç›¸ä¼¼åº¦ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åˆ°æ–°è¡¨ä¸­çš„å®Œæ•´æµç¨‹ã€‚ç³»ç»Ÿé‡‡ç”¨åŒç®—æ³•å¹¶è¡Œè®¡ç®—ï¼Œç¡®ä¿ç»“æœå‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

This system implements a complete process of extracting product data from two database tables, calculating product similarity through a double-layer loop comparison, and storing the results in a new table. The system employs dual-algorithm parallel computation to ensure the accuracy and reliability of the results.

## æ ¸å¿ƒå¤„ç†æµç¨‹ / Core Processing Flow

```mermaid
flowchart TD
    A[å¼€å§‹ / Start] --> B[è¿æ¥æ•°æ®åº“ / Connect to DB]
    B --> C[æå–å•†å“åç§°æ•°æ® / Extract Product Name Data]
    B --> D[æå–å•†å“è§„æ ¼æ•°æ® / Extract Product Spec Data]
    B --> E[æå–å“ç‰Œæ•°æ® / Extract Brand Data]
    E --> F[å¤„ç†å“ç‰Œæ˜ å°„ / Process Brand Mapping]
    F --> G[åˆå§‹åŒ–ç»“æœåˆ—è¡¨ / Initialize Result List]
    C --> H[å•†å“åç§°åˆ—è¡¨ / Product Name List]
    D --> I[å•†å“è§„æ ¼åˆ—è¡¨ / Product Spec List]
    H --> J[åŒå±‚å¾ªç¯æ¯”å¯¹ / Double Loop Comparison]
    I --> J
    J --> K[å‡†å¤‡è¾“å…¥æ•°æ® / Prepare Input Data]
    K --> L[æ–¹æ³•Aè®¡ç®—ç›¸ä¼¼åº¦ / Method A Calculate Similarity]
    K --> M[æ–¹æ³•Bè®¡ç®—ç›¸ä¼¼åº¦ / Method B Calculate Similarity]
    L --> N[å­˜å‚¨æ–¹æ³•Aç»“æœ / Store Method A Result]
    M --> N
    N --> O{éå†å®Œæˆ? / Traversal Complete?}
    O -->|å¦ / No| J
    O -->|æ˜¯ / Yes| P[å…³é—­æ•°æ®åº“è¿æ¥ / Close DB Connection]
    P --> Q[ç»“æŸ / End]
```

## æ•°æ®å¤„ç†æµç¨‹è¯¦è§£ / Data Processing Flow Details

### 1. æ•°æ®æå–é˜¶æ®µ / Data Extraction Phase

```mermaid
sequenceDiagram
    participant Main as ä¸»ç¨‹åº / Main Program
    participant DB as æ•°æ®åº“ / Database
    participant BrandModule as å“ç‰Œå¤„ç†æ¨¡å— / Brand Processing Module
    
    Main->>DB: è¿æ¥è¯·æ±‚ / Connection Request
    DB-->>Main: è¿æ¥æˆåŠŸ / Connection Successful
    Main->>DB: æŸ¥è¯¢å•†å“åç§°(spmc) / Query Product Names (spmc)
    DB-->>Main: è¿”å›å•†å“åç§°åˆ—è¡¨ / Return Product Name List
    Main->>DB: æŸ¥è¯¢å•†å“è§„æ ¼(gg) / Query Product Specs (gg)
    DB-->>Main: è¿”å›å•†å“è§„æ ¼åˆ—è¡¨ / Return Product Spec List
    Main->>DB: æŸ¥è¯¢å“ç‰Œæ•°æ®(pp) / Query Brand Data (pp)
    DB-->>Main: è¿”å›å“ç‰Œåˆ—è¡¨ / Return Brand List
    Main->>BrandModule: å‘é€å“ç‰Œæ•°æ® / Send Brand Data
    BrandModule-->>Main: è¿”å›å“ç‰Œæ˜ å°„å­—å…¸ / Return Brand Mapping Dict
```

### 2. ç›¸ä¼¼åº¦è®¡ç®—é˜¶æ®µ / Similarity Calculation Phase

```mermaid
graph LR
    %% å®šä¹‰ä¸»æµç¨‹èŠ‚ç‚¹
    DoubleLoop[åŒå±‚å¾ªç¯æ¯”å¯¹ / Double Loop Comparison]
    MethodA[æ–¹æ³•A / Method A]
    MethodB[æ–¹æ³•B / Method B]
    Result[ç»“æœè¡¨ / Result Table]
    
    %% å®šä¹‰å­å›¾ï¼šåŒå±‚å¾ªç¯æ¯”å¯¹é€»è¾‘
    subgraph SubGraph [åŒå±‚å¾ªç¯æ¯”å¯¹é€»è¾‘]
        direction TB
        Spec1[å•†å“è§„æ ¼1 / Spec 1]
        Spec2[å•†å“è§„æ ¼2 / Spec 2]
        Name1[å•†å“åç§°1 / Name 1]
        Name2[å•†å“åç§°2 / Name 2]
        Name3[å•†å“åç§°3 / Name 3]
        
        %% å­å›¾å†…éƒ¨è¿æ¥
        Spec1 --> Name1
        Spec1 --> Name2
        Spec1 --> Name3
        Spec2 --> Name1
        Spec2 --> Name2
        Spec2 --> Name3
    end
    
    %% ä¸»æµç¨‹è¿æ¥
    DoubleLoop --> MethodA
    DoubleLoop --> MethodB
    MethodA --> Result
    MethodB --> Result
```

### 3. ç»“æœå­˜å‚¨é˜¶æ®µ / Result Storage Phase

```mermaid
pie
    title ç»“æœè¡¨ç»“æ„å æ¯” / Result Table Structure Proportion
    "å•†å“åç§° / Product Name" : 25
    "å•†å“è§„æ ¼ / Product Spec" : 25
    "æ–¹æ³•Aç›¸ä¼¼åº¦ / Method A Similarity" : 25
    "æ–¹æ³•Bç›¸ä¼¼åº¦ / Method B Similarity" : 25
```

## æ ¸å¿ƒç®—æ³•å®ç° / Core Algorithm Implementation

# å•†å“ç›¸ä¼¼åº¦è®¡ç®—ç³»ç»Ÿæ–‡æ¡£ / Product Similarity Calculation System Documentation

## æ–¹æ³•Aï¼šåŸºäºç‰¹å¾æå–çš„ç›¸ä¼¼åº¦è®¡ç®— / Method A: Feature Extraction-Based Similarity Calculation

### æ ¸å¿ƒç®—æ³•æµç¨‹å›¾ / Core Algorithm Flowchart

```mermaid
graph TD
    A[è¾“å…¥å•†å“åç§°å¯¹ / Input Product Name Pair] --> B[æ–‡æœ¬é¢„å¤„ç† / Text Preprocessing]
    B --> C[ç‰¹å¾æå– / Feature Extraction]
    C --> D[ç‰¹å¾ç›¸ä¼¼åº¦è®¡ç®— / Feature Similarity Calculation]
    D --> E[åŠ æƒç»¼åˆ / Weighted Synthesis]
    E --> F[æœ€ç»ˆç›¸ä¼¼åº¦ / Final Similarity]
```

### å…³é”®åŠŸèƒ½å®ç° / Key Function Implementation

```python
def calculate_similarity(input_data, config_path=None, debug=False, sppp=None):
    """
    å•†å“åç§°ç›¸ä¼¼åº¦è®¡ç®—ä¸»å‡½æ•° / Main function for product name similarity calculation
    åŸºäºç‰¹å¾æå–å’ŒåŠ æƒè®¡ç®—çš„ç›¸ä¼¼åº¦ç®—æ³• / Similarity algorithm based on feature extraction and weighted calculation
    
    å‚æ•° / Parameters:
        input_data: åŒ…å«ä¸¤ä¸ªå•†å“ä¿¡æ¯çš„åˆ—è¡¨ / List containing two product information items
        sppp: å“ç‰Œæ˜ å°„å­—å…¸ / Brand mapping dictionary
        
    è¿”å› / Returns:
        ç›¸ä¼¼åº¦åˆ†æ•° (0-1ä¹‹é—´çš„æµ®ç‚¹æ•°) / Similarity score (float between 0-1)
    """
    try:
        # åˆå§‹åŒ–è®¡ç®—å™¨ï¼ˆä¼ å…¥spppï¼‰/ Initialize calculator (pass sppp)
        calculator = ProductSimilarityCalculator(config_path, debug, sppp)
        
        # å¤„ç†è¾“å…¥æ•°æ®ï¼ˆç¡®ä¿ä¸ºä¸€å¯¹æ–‡æœ¬ï¼‰/ Process input data (ensure it's a pair of texts)
        if isinstance(input_data, list) and len(input_data) == 2:
            str1 = str(input_data[0]).strip() if input_data[0] is not None else ""
            str2 = str(input_data[1]).strip() if input_data[1] is not None else ""
        else:
            raise TypeError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯åŒ…å«ä¸¤ä¸ªæ–‡æœ¬çš„åˆ—è¡¨ / Input data must be a list containing two texts")
        
        # è®¡ç®—å•å¯¹æ–‡æœ¬çš„ç›¸ä¼¼åº¦ / Calculate similarity for a single pair of texts
        similarity = calculator.calculate_pair_similarity(str1, str2)
        return similarity
    
    except Exception as e:
        return 0.0

class ProductSimilarityCalculator:
    def preprocess_text(self, text):
        """æ–‡æœ¬é¢„å¤„ç† / Text Preprocessing"""
        # è½¬æ¢ä¸ºå°å†™å¹¶å»é™¤é¦–å°¾ç©ºæ ¼ / Convert to lowercase and remove leading/trailing spaces
        text = text.lower().strip()
        
        # ç»Ÿä¸€ç‰¹æ®Šå­—ç¬¦ / Unify special characters
        text = re.sub(r'[*/Ã—x&ï¼ˆï¼‰ã€ã€‘ã€ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"ã€Œã€"''\-_]', ' ', text)
        
        # å“ç‰Œç¼©å†™æ›¿æ¢ / Brand abbreviation replacement
        for abbr, brand in self.brand_mapping.items():
            text = re.sub(rf'\b{re.escape(abbr)}\b', brand.lower(), text)
        
        # åŒä¹‰è¯æ›¿æ¢ / Synonym replacement
        for syn, words in self.synonyms.items():
            for word in words:
                text = re.sub(rf'\b{re.escape(word.lower())}\b', syn.lower(), text)
        
        # æ•°å­—å•ä½æ ‡å‡†åŒ– / Digital unit standardization
        text = re.sub(r'(\d+)\s*(gb|g)\b', r'\1gb', text)
        text = re.sub(r'(\d+)\s*(ml|æ¯«å‡)\b', r'\1ml', text)
        # ...å…¶ä»–å•ä½æ ‡å‡†åŒ– / ...Other unit standardization
        
        # ç§»é™¤åœç”¨è¯ / Remove stop words
        for word in self.stop_words:
            text = re.sub(rf'\b{re.escape(word)}\b', '', text)
        
        # åˆå¹¶å¤šä¸ªç©ºæ ¼ / Merge multiple spaces
        return re.sub(r'\s+', ' ', text).strip()
    
    def extract_features(self, text):
        """æå–æ–‡æœ¬ç‰¹å¾ / Extract Text Features"""
        brand = self._extract_brand(text)
        model = self._extract_model(text, brand)
        
        features = {
            "brand": brand,
            "model": model,
            "specs": self._extract_specs(text),
            "keywords": self._extract_keywords(text, brand, model),
            "digits": ''.join(re.findall(r'\d+', text)),
            "color": self._extract_color(text)
        }
        return features
    
    def calculate_feature_similarity(self, features1, features2):
        """è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦ / Calculate Feature Similarity"""
        # è®¡ç®—å„ç‰¹å¾ç»´åº¦ç›¸ä¼¼åº¦ / Calculate similarity for each feature dimension
        brand_sim = self._calculate_brand_similarity(features1["brand"], features2["brand"])
        model_sim = self._calculate_model_similarity(features1["model"], features2["model"])
        spec_sim = self._calculate_spec_similarity(features1["specs"], features2["specs"])
        keyword_sim = self._calculate_keyword_similarity(features1["keywords"], features2["keywords"])
        digit_sim = self._calculate_digit_similarity(features1["digits"], features2["digits"])
        color_sim = self._calculate_color_similarity(features1["color"], features2["color"])
        
        # åŠ æƒç»¼åˆ / Weighted synthesis
        weights = self.feature_weights
        total_sim = (
            weights["brand"] * brand_sim +
            weights["model"] * model_sim +
            weights["specs"] * spec_sim +
            weights["keywords"] * keyword_sim +
            weights["digits"] * digit_sim +
            weights["color"] * color_sim
        )
        
        # åº”ç”¨æå‡è§„åˆ™ / Apply enhancement rules
        if brand_sim > 0.8 and model_sim > 0.7:
            total_sim = max(total_sim, self.min_similarity.get("model_match", 0.8))
        elif brand_sim > 0.8:
            total_sim = max(total_sim, self.min_similarity.get("brand_match", 0.7))
        
        return min(max(total_sim, 0.0), 1.0)
```

## æ–¹æ³•Bï¼šåŸºäºæ··åˆæ¨¡å‹çš„ç›¸ä¼¼åº¦è®¡ç®— / Method B: Hybrid Model-Based Similarity Calculation

### æ ¸å¿ƒç®—æ³•æµç¨‹å›¾ / Core Algorithm Flowchart

```mermaid
graph TD
    A[è¾“å…¥å•†å“åç§°å¯¹ / Input Product Name Pair] --> B[æ–‡æœ¬é¢„å¤„ç† / Text Preprocessing]
    B --> C[TF-IDFå‘é‡åŒ– / TF-IDF Vectorization]
    C --> D[ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®— / Cosine Similarity Calculation]
    B --> E[å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®— / Multi-dimensional Similarity Calculation]
    E --> F[åŠ æƒç»¼åˆ / Weighted Synthesis]
    D --> F
    F --> G[æœ€ç»ˆç›¸ä¼¼åº¦ / Final Similarity]
```

### å…³é”®åŠŸèƒ½å®ç° / Key Function Implementation

```python
def calculate_similarities(input_data):
    """
    å•†å“ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•B / Product Similarity Calculation Method B
    åŸºäºTF-IDFå’Œå¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®—çš„æ··åˆç®—æ³• / Hybrid algorithm based on TF-IDF and multi-dimensional similarity calculation
    
    å‚æ•° / Parameters:
        input_data: åŒ…å«ä¸¤ä¸ªå•†å“ä¿¡æ¯çš„åˆ—è¡¨ / List containing two product information items
        
    è¿”å› / Returns:
        ç›¸ä¼¼åº¦åˆ†æ•° (0-1ä¹‹é—´çš„æµ®ç‚¹æ•°) / Similarity score (float between 0-1)
    """
    # è¾“å…¥æ ¼å¼æ ¡éªŒä¸æ ‡å‡†åŒ– / Input format validation and standardization
    if isinstance(input_data, (list, tuple)) and len(input_data) == 2:
        title_pairs = [input_data]
    else:
        raise TypeError("è¾“å…¥å¿…é¡»æ˜¯å•ä¸ªäºŒå…ƒç»„æˆ–äºŒå…ƒç»„åˆ—è¡¨ / Input must be a single tuple or list of tuples")
    
    # æå–æ‰€æœ‰æ ‡é¢˜æ„å»ºè¯­æ–™åº“ / Extract all titles to build a corpus
    all_titles = []
    for t1, t2 in title_pairs:
        processed_t1 = preprocess_text(t1) if t1 is not None else ""
        processed_t2 = preprocess_text(t2) if t2 is not None else ""
        all_titles.append(processed_t1)
        all_titles.append(processed_t2)
    
    # åˆ›å»ºTF-IDFå‘é‡åŒ–å™¨ / Create TF-IDF vectorizer
    vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), token_pattern=None)
    tfidf_matrix = vectorizer.fit_transform(all_titles)
    
    preprocessed = [
        (preprocess_text(t1) if t1 is not None else "", 
         preprocess_text(t2) if t2 is not None else "") 
        for t1, t2 in title_pairs
    ]
    results = []
    
    for i, (t1, t2) in enumerate(preprocessed):
        # è®¡ç®—TF-IDFä½™å¼¦ç›¸ä¼¼åº¦ / Calculate TF-IDF cosine similarity
        idx1 = i * 2
        idx2 = i * 2 + 1
        tfidf_sim = cosine_similarity(tfidf_matrix[idx1], tfidf_matrix[idx2])[0][0]
        
        # è®¡ç®—å…¶ä»–ç›¸ä¼¼åº¦ / Calculate other similarities
        other_sim = compute_similarity(t1, t2)
        
        # è°ƒæ•´æƒé‡ï¼šTF-IDFå 20%ï¼Œå…¶ä»–æ–¹æ³•å 80% / Adjust weights: TF-IDF 20%, other methods 80%
        final_sim = 0.2 * tfidf_sim + 0.8 * other_sim
        results.append(round(final_sim, 4))
    
    return results[0] if results else 0.0

def compute_similarity(t1, t2):
    """æ™ºèƒ½ç›¸ä¼¼åº¦è®¡ç®—å¼•æ“ / Intelligent Similarity Calculation Engine"""
    # æ ¸å¿ƒç›¸ä¼¼åº¦ç»´åº¦ / Core similarity dimensions
    char_sim = character_similarity(t1, t2)
    token_sim = token_similarity(t1, t2)
    num_sim = numeric_similarity(t1, t2)
    order_sim = order_similarity(t1, t2)
    semantic_sim = semantic_analysis(t1, t2)
    
    # åŠ¨æ€æƒé‡åˆ†é… / Dynamic weight allocation
    metrics = [char_sim, token_sim, num_sim, order_sim, semantic_sim]
    weights = adaptive_weights(metrics)
    
    # åŠ æƒç»¼åˆ / Weighted synthesis
    final_sim = sum(w * m for w, m in zip(weights, metrics))
    return max(0.0, min(1.0, final_sim))

def semantic_analysis(text1, text2):
    """åŠ¨æ€è¯­ä¹‰åˆ†æ / Dynamic Semantic Analysis"""
    # 1. å…³é”®ç‰¹å¾å·®å¼‚æ£€æµ‹ / Key feature difference detection
    diff_features = detect_feature_differences(text1, text2)
    if diff_features > 3:  # å¤šä¸ªå…³é”®ç‰¹å¾ä¸åŒ / Multiple key features differ
        return max(0.1, 0.7 - diff_features * 0.1)
    
    # 2. å‹å·ä¸€è‡´æ€§æ£€æµ‹ / Model consistency detection
    model_match = detect_model_consistency(text1, text2)
    if not model_match:
        return 0.4
    
    # 3. å±æ€§å·®å¼‚è¯„ä¼° / Attribute difference evaluation
    return evaluate_attribute_differences(text1, text2)
```

## ç³»ç»Ÿé›†æˆæµç¨‹ / System Integration Flow

### æ•°æ®å¤„ç†æµç¨‹å›¾ / Data Processing Flowchart

```mermaid
sequenceDiagram
    participant Main as ä¸»ç¨‹åº / Main Program
    participant DB as æ•°æ®åº“ / Database
    participant MethodA as æ–¹æ³•A / Method A
    participant MethodB as æ–¹æ³•B / Method B
    
    Main->>DB: è¿æ¥æ•°æ®åº“ / Connect to Database
    Main->>DB: è·å–å•†å“åç§°(spmc) / Get Product Names (spmc)
    DB-->>Main: è¿”å›å•†å“åç§°åˆ—è¡¨ / Return Product Name List
    Main->>DB: è·å–å•†å“è§„æ ¼(gg) / Get Product Specs (gg)
    DB-->>Main: è¿”å›å•†å“è§„æ ¼åˆ—è¡¨ / Return Product Spec List
    Main->>DB: è·å–å“ç‰Œæ•°æ®(pp) / Get Brand Data (pp)
    DB-->>Main: è¿”å›å“ç‰Œåˆ—è¡¨ / Return Brand List
    Main->>MethodA: å¤„ç†å“ç‰Œæ•°æ® / Process Brand Data
    MethodA-->>Main: å“ç‰Œæ˜ å°„å­—å…¸ / Brand Mapping Dictionary
    
    loop åŒå±‚å¾ªç¯æ¯”å¯¹ / Double Loop Comparison
        Main->>MethodA: å‘é€å•†å“åç§°+è§„æ ¼ / Send Product Name+Spec
        MethodA-->>Main: è¿”å›æ–¹æ³•Aç›¸ä¼¼åº¦ / Return Method A Similarity
        Main->>MethodB: å‘é€å•†å“åç§°+è§„æ ¼ / Send Product Name+Spec
        MethodB-->>Main: è¿”å›æ–¹æ³•Bç›¸ä¼¼åº¦ / Return Method B Similarity
        Main->>DB: å­˜å‚¨ç»“æœ / Store Results
    end
    
    Main->>DB: å…³é—­è¿æ¥ / Close Connection
```

### æ ¸å¿ƒé›†æˆä»£ç  / Core Integration Code

```python
# æ•°æ®åº“è¿æ¥é…ç½® / Database Connection Configuration
db_config = [
    {"name": "DataSource", "value": "192.168.99.179"},
    {"name": "DbName", "value": "pricedb"},
    {"name": "Port", "value": 9826},
    {"name": "UserName", "value": "sa"},
    {"name": "Pwd", "value": "U2VydmVyY2YxZThj"}
]

æ•°æ®åº“å¯¹è±¡ = Database.DBConnect(SZEnv['rpa'], 1, db_config)

try:
    # ä»æ•°æ®åº“è·å–æ•°æ® / Get data from database
    spmc = Database.SingleSQLQuery(SZEnv['rpa'], æ•°æ®åº“å¯¹è±¡, "SELECT TOP 13 spmc FROM cj_spzd")
    spxx = Database.SingleSQLQuery(SZEnv['rpa'], æ•°æ®åº“å¯¹è±¡, "SELECT TOP 6 gg FROM cj_rw_spxx")
    brand = Database.SingleSQLQuery(SZEnv['rpa'], æ•°æ®åº“å¯¹è±¡, "SELECT pp FROM cj_spzd")
    
    # å¤„ç†å“ç‰Œæ˜ å°„ / Process brand mapping
    brand_list = Basic.SetVariable(SZEnv['rpa'], brand, var_ret=1)
    sppp = run_module("code_modules.è·å–å“ç‰Œåç§°", "main", brand_list)
    
    # åŒå±‚å¾ªç¯æ¯”å¯¹ / Double loop comparison
    for å½“å‰spxx in spxx:
        for å½“å‰spmc in spmc:
            # å‡†å¤‡è¾“å…¥æ•°æ® / Prepare input data
            input_data = [å½“å‰spmc, å½“å‰spxx]
            
            # è°ƒç”¨æ–¹æ³•Aè®¡ç®—ç›¸ä¼¼åº¦ / Call Method A to calculate similarity
            result_a = calculate_similarity(input_data, sppp=sppp)
            
            # è°ƒç”¨æ–¹æ³•Bè®¡ç®—ç›¸ä¼¼åº¦ / Call Method B to calculate similarity
            result_b = calculate_similarities(input_data)
            
            # å­˜å‚¨ç»“æœåˆ°æ•°æ®åº“ / Store results to database
            Database.SQLExecute(
                SZEnv['rpa'], 
                æ•°æ®åº“å¯¹è±¡, 
                "INSERT INTO cj_sppp (spmc, gg, similarity_a, similarity_b) VALUES (?, ?, ?, ?)", 
                [å½“å‰spmc, å½“å‰spxx, result_a, result_b]
            )
            
except Exception as ex:
    # å¼‚å¸¸å¤„ç† / Exception handling
    Basic.DebugOutput(SZEnv['rpa'], SZEnv['rpa'].format_ex(ex))
finally:
    # å…³é—­æ•°æ®åº“è¿æ¥ / Close database connection
    Database.CloseDBConnect(SZEnv['rpa'], æ•°æ®åº“å¯¹è±¡)
```

# å“ç‰Œåç§°æå–æ¨¡å—æ–‡æ¡£ / Brand Name Extraction Module Documentation

## åŠŸèƒ½æ¦‚è¿° / Function Overview
è¿™ä¸ªæ¨¡å—è´Ÿè´£ä»åŸå§‹å“ç‰Œæ•°æ®ä¸­æå–æ ‡å‡†åŒ–çš„ä¸­æ–‡å“ç‰Œåç§°ï¼Œå¹¶è¿›è¡Œå»é‡å¤„ç†ã€‚å®ƒä¸“é—¨ç”¨äºå¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦ã€è‹±æ–‡æˆ–æ··åˆæ–‡æœ¬çš„å“ç‰Œæ•°æ®ï¼Œæå–å‡ºçº¯å‡€çš„ä¸­æ–‡å“ç‰Œåç§°ã€‚

This module is responsible for extracting standardized Chinese brand names from raw brand data and performing deduplication. It is specifically designed to process brand data containing special characters, English, or mixed text, extracting pure Chinese brand names.

## æ ¸å¿ƒç®—æ³•æµç¨‹å›¾ / Core Algorithm Flowchart

```mermaid
graph TD
    A[è¾“å…¥å“ç‰Œåˆ—è¡¨ / Input Brand List] --> B[éå†æ¯ä¸ªå“ç‰Œ / Iterate Each Brand]
    B --> C{æ˜¯å¦ä¸ºå­—ç¬¦ä¸²? / Is String?}
    C -->|æ˜¯ / Yes| D[æå–æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ / Extract All Chinese Characters]
    C -->|å¦ / No| E[å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸² / Try Convert to String]
    E --> F{è½¬æ¢æˆåŠŸ? / Conversion Successful?}
    F -->|æ˜¯ / Yes| D
    F -->|å¦ / No| G[è·³è¿‡è¯¥å“ç‰Œ / Skip This Brand]
    D --> H[æ‹¼æ¥ä¸­æ–‡å­—ç¬¦ / Concatenate Chinese Characters]
    H --> I[æ·»åŠ åˆ°ç»“æœåˆ—è¡¨ / Add to Result List]
    I --> J[ç»“æœå»é‡ / Result Deduplication]
    J --> K[è¿”å›å”¯ä¸€å“ç‰Œåˆ—è¡¨ / Return Unique Brand List]
```

## å…³é”®åŠŸèƒ½å®ç° / Key Function Implementation

```python
import re

def main(input_list):
    """æ¸…æ´—å¹¶æå–å“ç‰Œåç§°çš„æ ¸å¿ƒæ–¹æ³• / Core method for cleaning and extracting brand names
    
    å‚æ•° / Parameters:
        input_list: åŸå§‹å“ç‰Œæ•°æ®åˆ—è¡¨ï¼Œå¯èƒ½åŒ…å«å­—ç¬¦ä¸²ã€Noneæˆ–å…¶ä»–ç±»å‹ / Raw brand data list, may contain strings, None, or other types
        
    è¿”å› / Returns:
        å»é‡åçš„ä¸­æ–‡å“ç‰Œåç§°åˆ—è¡¨ / Deduplicated Chinese brand name list
    """
    # åˆå§‹åŒ–ç»“æœåˆ—è¡¨ / Initialize result list
    cleaned_brands = []
    
    # éå†è¾“å…¥åˆ—è¡¨ä¸­çš„æ¯ä¸ªå“ç‰Œ / Iterate each brand in the input list
    for brand in input_list:
        # å¤„ç†éå­—ç¬¦ä¸²ç±»å‹ / Handle non-string types
        if not isinstance(brand, str):
            if brand is None:
                continue
            try:
                brand = str(brand)
            except:
                continue
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ / Use regex to extract all Chinese characters
        chinese_chars = re.findall(r'[\u4e00-\u9fff]+', brand)
        
        # å¦‚æœæ‰¾åˆ°æ±‰å­—éƒ¨åˆ†ï¼Œæ‹¼æ¥æˆå­—ç¬¦ä¸² / If Chinese characters found, concatenate into string
        if chinese_chars:
            brand_name = ''.join(chinese_chars)
            cleaned_brands.append(brand_name)
    
    # å»é‡å¤„ç†ï¼ˆä¿ç•™åŸå§‹é¡ºåºï¼‰/ Deduplication (preserve original order)
    seen = set()
    unique_brands = []
    for brand in cleaned_brands:
        if brand not in seen:
            seen.add(brand)
            unique_brands.append(brand)
    
    return unique_brands
```

## å¤„ç†æµç¨‹è¯¦è§£ / Processing Flow Details

### 1. è¾“å…¥å¤„ç† / Input Processing
- æ¥å—åŸå§‹å“ç‰Œæ•°æ®åˆ—è¡¨ / Accept raw brand data list
- åˆ—è¡¨å…ƒç´ å¯èƒ½æ˜¯å„ç§ç±»å‹ï¼ˆå­—ç¬¦ä¸²ã€Noneã€æ•°å­—ç­‰ï¼‰/ List elements may be of various types (strings, None, numbers, etc.)

### 2. æ•°æ®ç±»å‹å¤„ç† / Data Type Processing
```mermaid
flowchart TD
    A[åŸå§‹æ•°æ® / Raw Data] --> B{æ˜¯å¦ä¸ºå­—ç¬¦ä¸²? / Is String?}
    B -->|æ˜¯ / Yes| C[ç›´æ¥å¤„ç† / Direct Processing]
    B -->|å¦ / No| D{æ˜¯å¦ä¸ºNone? / Is None?}
    D -->|æ˜¯ / Yes| E[è·³è¿‡ / Skip]
    D -->|å¦ / No| F[å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸² / Try Convert to String]
    F --> G{è½¬æ¢æˆåŠŸ? / Conversion Successful?}
    G -->|æ˜¯ / Yes| C
    G -->|å¦ / No| E
```

### 3. ä¸­æ–‡æå– / Chinese Extraction
- ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ `[\u4e00-\u9fff]+` åŒ¹é…æ‰€æœ‰ä¸­æ–‡å­—ç¬¦ / Use regex `[\u4e00-\u9fff]+` to match all Chinese characters
- æå–ç»“æœå¯èƒ½æ˜¯å¤šä¸ªä¸è¿ç»­çš„ä¸­æ–‡ç‰‡æ®µ / Extraction result may be multiple discontinuous Chinese fragments
- å°†æå–çš„ä¸­æ–‡ç‰‡æ®µæ‹¼æ¥æˆå®Œæ•´å­—ç¬¦ä¸² / Concatenate extracted Chinese fragments into complete strings

### 4. ç»“æœå»é‡ / Result Deduplication
- ä½¿ç”¨é›†åˆ(Set)æ£€æµ‹é‡å¤é¡¹ / Use Set to detect duplicates
- ä¿ç•™åŸå§‹é¡ºåºçš„ç‹¬ç‰¹å“ç‰Œåˆ—è¡¨ / Unique brand list preserving original order
- ç¡®ä¿ç»“æœä¸­æ¯ä¸ªå“ç‰Œåç§°åªå‡ºç°ä¸€æ¬¡ / Ensure each brand name appears only once in the result

## ä½¿ç”¨ç¤ºä¾‹ / Usage Example

### è¾“å…¥æ•°æ® / Input Data
```python
raw_brands = [
    "Nike-è€å…‹",
    "Adidasé˜¿è¿ªè¾¾æ–¯",
    "Appleè‹¹æœ",
    None,
    12345,
    "åä¸º/HUAWEI",
    "å°ç±³ç§‘æŠ€",
    "ä¸‰æ˜Ÿç”µå­-Samsung",
    "æ ¼åŠ›-GREE"
]
```

### å¤„ç†è¿‡ç¨‹ / Processing
```python
cleaned = main(raw_brands)
```

### è¾“å‡ºç»“æœ / Output Result
```
['è€å…‹', 'é˜¿è¿ªè¾¾æ–¯', 'è‹¹æœ', 'åä¸º', 'å°ç±³ç§‘æŠ€', 'ä¸‰æ˜Ÿç”µå­', 'æ ¼åŠ›']
```

## é›†æˆåˆ°ä¸»æµç¨‹ / Integration into Main Flow

### åœ¨å•†å“ç›¸ä¼¼åº¦ç³»ç»Ÿä¸­çš„è°ƒç”¨ / Call in Product Similarity System
```python
# ä»æ•°æ®åº“è·å–åŸå§‹å“ç‰Œæ•°æ® / Get raw brand data from database
brand_data = Database.SingleSQLQuery(SZEnv['rpa'], æ•°æ®åº“å¯¹è±¡, "SELECT pp FROM cj_spzd")

# å¤„ç†å“ç‰Œæ•°æ® / Process brand data
cleaned_brands = main(brand_data)

# æ„å»ºå“ç‰Œæ˜ å°„å­—å…¸ / Build brand mapping dictionary
sppp = {brand: brand for brand in cleaned_brands}

# å°†å“ç‰Œæ˜ å°„ä¼ é€’ç»™ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³• / Pass brand mapping to similarity calculation method
result = calculate_similarity(input_data, sppp=sppp)
```

### æ•°æ®å¤„ç†æµç¨‹å›¾ / Data Processing Flowchart
```mermaid
sequenceDiagram
    participant DB as æ•°æ®åº“ / Database
    participant BrandModule as å“ç‰Œå¤„ç†æ¨¡å— / Brand Processing Module
    participant SimModule as ç›¸ä¼¼åº¦è®¡ç®—æ¨¡å— / Similarity Calculation Module
    
    DB->>BrandModule: åŸå§‹å“ç‰Œæ•°æ® / Raw Brand Data
    BrandModule->>BrandModule: æ¸…æ´—å’Œæå–ä¸­æ–‡ / Clean and Extract Chinese
    BrandModule->>BrandModule: å»é‡å¤„ç† / Deduplication
    BrandModule->>SimModule: å“ç‰Œæ˜ å°„å­—å…¸(sppp) / Brand Mapping Dictionary (sppp)
    SimModule->>SimModule: ä½¿ç”¨spppè¿›è¡Œç›¸ä¼¼åº¦è®¡ç®— / Use sppp for Similarity Calculation
    SimModule->>DB: å­˜å‚¨ç»“æœ / Store Results
```

## å¤„ç†è§„åˆ™è¯´æ˜ / Processing Rules Description

| è¾“å…¥ç±»å‹ / Input Type | å¤„ç†æ–¹å¼ / Processing Method | ç¤ºä¾‹è¾“å…¥ / Example Input | ç¤ºä¾‹è¾“å‡º / Example Output |
|----------|----------|----------|----------|
| çº¯ä¸­æ–‡ / Pure Chinese | ç›´æ¥æå– / Direct Extraction | "åä¸ºæ‰‹æœº" | "åä¸ºæ‰‹æœº" |
| ä¸­è‹±æ··åˆ / Chinese-English Mixed | æå–ä¸­æ–‡éƒ¨åˆ† / Extract Chinese Part | "Appleè‹¹æœ" | "è‹¹æœ" |
| å¸¦ç‰¹æ®Šå­—ç¬¦ / With Special Characters | æå–ä¸­æ–‡éƒ¨åˆ† / Extract Chinese Part | "ä¸‰æ˜Ÿ/Samsung" | "ä¸‰æ˜Ÿ" |
| Noneå€¼ / None Value | è·³è¿‡å¤„ç† / Skip Processing | None | (ä¸åŒ…å« / Not Included) |
| æ•°å­— / Numbers | è·³è¿‡å¤„ç† / Skip Processing | 12345 | (ä¸åŒ…å« / Not Included) |
| æ— ä¸­æ–‡ / No Chinese | è·³è¿‡å¤„ç† / Skip Processing | "Samsung" | (ä¸åŒ…å« / Not Included) |

## åº”ç”¨åœºæ™¯ / Application Scenarios

1. **ç”µå•†æ•°æ®æ¸…æ´—**ï¼šä»å•†å“ä¿¡æ¯ä¸­æå–çº¯å‡€å“ç‰Œåç§° / **E-commerce Data Cleaning**: Extract pure brand names from product information
2. **å“ç‰Œåˆ†æ**ï¼šç»Ÿè®¡ä¸åŒå“ç‰Œçš„å‡ºç°é¢‘ç‡ / **Brand Analysis**: Count occurrence frequency of different brands
3. **æ•°æ®æ ‡å‡†åŒ–**ï¼šä¸ºä¸åŒæ¥æºçš„å“ç‰Œæ•°æ®æä¾›ç»Ÿä¸€æ ¼å¼ / **Data Standardization**: Provide unified format for brand data from different sources
4. **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šä¸ºå•†å“ç›¸ä¼¼åº¦ç®—æ³•æä¾›æ ‡å‡†åŒ–çš„å“ç‰Œè¾“å…¥ / **Similarity Calculation**: Provide standardized brand input for product similarity algorithms

## æ€§èƒ½ä¼˜åŒ– / Performance Optimization

- **é«˜æ•ˆæ­£åˆ™**ï¼šä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æé«˜åŒ¹é…æ•ˆç‡ / **Efficient Regex**: Use precompiled regex to improve matching efficiency
- **æƒ°æ€§å¤„ç†**ï¼šåªåœ¨å¿…è¦æ—¶è¿›è¡Œç±»å‹è½¬æ¢ / **Lazy Processing**: Perform type conversion only when necessary
- **é›†åˆå»é‡**ï¼šO(1)æ—¶é—´å¤æ‚åº¦çš„é‡å¤æ£€æµ‹ / **Set Deduplication**: O(1) time complexity duplicate detection
- **çŸ­è·¯é€»è¾‘**ï¼šé‡åˆ°æ— æ•ˆæ•°æ®ç«‹å³è·³è¿‡ / **Short-circuit Logic**: Skip invalid data immediately

## æ€»æµç¨‹ç»“æœè¡¨ç¤ºä¾‹ / Overall Process Result Table Example

| å•†å“åç§° / Product Name | å•†å“è§„æ ¼ / Product Spec | æ–¹æ³•Aç›¸ä¼¼åº¦ / Method A Similarity | æ–¹æ³•Bç›¸ä¼¼åº¦ / Method B Similarity |
|---------------|-------------|------------|------------|
| iPhone 13 Pro | 128GB é“¶è‰² / Silver | 0.92 | 0.87 |
| åä¸º Mate 50 / Huawei Mate 50 | 256GB é»‘è‰² / Black | 0.85 | 0.82 |
| å°ç±³ 12 Ultra / Xiaomi 12 Ultra | 512GB è“è‰² / Blue | 0.78 | 0.76 |
| ä¸‰æ˜Ÿ Galaxy S22 / Samsung Galaxy S22 | 128GB ç™½è‰² / White | 0.91 | 0.88 |
| iPad Pro 2022 | 256GB ç°è‰² / Gray | 0.83 | 0.79 |

## ç³»ç»Ÿä¼˜åŠ¿å¯¹æ¯” / System Advantage Comparison

| ç‰¹æ€§ / Feature | æ–¹æ³•A / Method A | æ–¹æ³•B / Method B |
|------|-------|-------|
| æ ¸å¿ƒç®—æ³• / Core Algorithm | åŸºäºè§„åˆ™çš„ç‰¹å¾æå– / Rule-based Feature Extraction | æ··åˆæ¨¡å‹(TF-IDF+è¯­ä¹‰) / Hybrid Model (TF-IDF+Semantic) |
| å¤„ç†é€Ÿåº¦ / Processing Speed | âš¡ å¿«é€Ÿ / Fast | â³ ä¸­ç­‰ / Medium |
| å‡†ç¡®æ€§ / Accuracy | é«˜ï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰/ High (Structured Data) | éå¸¸é«˜ï¼ˆå¤æ‚åœºæ™¯ï¼‰/ Very High (Complex Scenarios) |
| é€‚ç”¨åœºæ™¯ / Applicable Scenario | æ ‡å‡†åŒ–å•†å“åç§° / Standardized Product Names | éç»“æ„åŒ–å•†å“æè¿° / Unstructured Product Descriptions |
| å¯è§£é‡Šæ€§ / Interpretability | âœ… é«˜ / High | âš ï¸ ä¸­ç­‰ / Medium |
| å“ç‰Œä¾èµ– / Brand Dependency | âœ… å¼ºä¾èµ– / Strong Dependency | âš ï¸ å¼±ä¾èµ– / Weak Dependency |
| è®¡ç®—å¤æ‚åº¦ / Computational Complexity | ä¸­ / Medium | é«˜ / High |

## ä½¿ç”¨æŒ‡å— / Usage Guide

1. **é…ç½®æ•°æ®åº“è¿æ¥** / **Configure Database Connection**ï¼š
   ```python
   # é…ç½®æ•°æ®åº“è¿æ¥å‚æ•° / Configure database connection parameters
   db_config = [
       {"name": "DataSource", "value": "192.168.99.179"},
       {"name": "DbName", "value": "pricedb"},
       {"name": "Port", "value": 9826},
       {"name": "UserName", "value": "sa"},
       {"name": "Pwd", "value": "U2VydmVyY2YxZThj"}
   ]
   
   æ•°æ®åº“å¯¹è±¡ = Database.DBConnect(SZEnv['rpa'], 1, db_config)
   ```

2. **æ‰§è¡Œç›¸ä¼¼åº¦è®¡ç®—** / **Execute Similarity Calculation**ï¼š
   ```python
   # åŒå±‚å¾ªç¯æ¯”å¯¹ / Double loop comparison
   for spec in product_specs:
       for name in product_names:
           input_data = [name, spec]
           result_a = calculate_similarity(input_data, sppp=brand_mapping)
           result_b = calculate_similarities(input_data)
           save_results(name, spec, result_a, result_b)
   ```

3. **ç»“æœåˆ†æ** / **Result Analysis**ï¼š
   ```sql
   -- æŸ¥è¯¢é«˜ç›¸ä¼¼åº¦å•†å“å¯¹ / Query high similarity product pairs
   SELECT * FROM cj_sppp 
   WHERE similarity_a > 0.8 
      OR similarity_b > 0.8
   ORDER BY similarity_a DESC;
   ```

4. **ä¼˜åŒ–å»ºè®®** / **Optimization Suggestions**ï¼š
   - å¯¹äºå¤§æ‰¹é‡æ•°æ®å¤„ç†ï¼Œè€ƒè™‘åˆ†æ‰¹å¤„ç† / For large-scale data processing, consider batch processing
   - å®šæœŸæ›´æ–°å“ç‰Œæ˜ å°„è¯å…¸ / Regularly update brand mapping dictionary
   - å¯¹æ–¹æ³•Bä½¿ç”¨GPUåŠ é€Ÿ / Use GPU acceleration for Method B
   - ä¸ºé«˜é¢‘æŸ¥è¯¢å»ºç«‹ç»“æœç¼“å­˜ / Establish result cache for high-frequency queries

## æŠ€æœ¯æ”¯æŒ / Technical Support

**è”ç³»ä¿¡æ¯** / **Contact Information**ï¼š  
ğŸ“§ smytz6@163.com  

**æœ€åæ›´æ–°** / **Last Updated**ï¼š2025-8-24

---
